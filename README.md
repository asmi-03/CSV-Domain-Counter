# CSV-Domain-Counter
This Node.js program reads a large CSV file (~1M rows) containing user emails, counts how many users belong to each email domain, and writes the results to a JSON file without loading the entire CSV into memory. It uses streams, readline, and backpressure for memory efficiency.

1Ô∏è‚É£ Prerequisites
Node.js v14+

ES modules support ("type": "module" in package.json)
{
  "type": "module",
  "scripts": {
    "start": "node code8.js"
  }
}
2Ô∏è‚É£ Project Structure
project/
‚îÇ
‚îú‚îÄ code8.js           # Main CSV processing script
‚îú‚îÄ data/
‚îÇ   ‚îî‚îÄ users.csv      # CSV file with user emails
‚îú‚îÄ out/               # Output folder (will be created automatically)
‚îî‚îÄ package.json
3Ô∏è‚É£ code8.js Explained
import fs from "fs";
import readline from "readline";
import path from "path";
Import built-in Node.js modules:

fs ‚Üí file system operations
readline ‚Üí read file line by line
path ‚Üí handle file paths
const inputFile = "data/users.csv";
const outputFile = "out/domains.json";
Define input CSV path and output JSON path.

async function main() {
 fs.mkdirSync(path.dirname(outputFile), { recursive: true });
Create the out folder if it doesn't exist, using recursive: true to create nested directories.
 if (!fs.existsSync(inputFile)) {
  throw new Error(`‚ùå Input file not found: ${inputFile}`);
 }
Check if the input CSV exists; throw an error if not.
 const domainCounts = {};
 let lineCount = 0;
 const startTime = Date.now();
domainCounts ‚Üí stores email domain counts.

lineCount ‚Üí tracks how many lines processed.
startTime ‚Üí to calculate processing duration.
 console.log("üìä Processing started...");
Log start message.
 const rl = readline.createInterface({
  input: fs.createReadStream(inputFile),
  crlfDelay: Infinity,
 });
Use readline with a stream to read the CSV line by line efficiently.
crlfDelay: Infinity ensures proper handling of \r\n (Windows line endings).
 for await (const line of rl) {
  if (lineCount === 0 && line.startsWith("id")) {
   lineCount++;
   continue;
  }
Skip the header line (id,email).

for await allows asynchronous iteration over each line in the file.
  const [, email] = line.split(",");
  if (!email || !email.includes("@")) continue;
Split the line by comma to extract the email column.

Skip invalid or empty emails.
  const domain = email.split("@")[1].trim();
  domainCounts[domain] = (domainCounts[domain] || 0) + 1;
Extract the domain from the email (after @).

Increment its count in domainCounts.
  lineCount++;
  if (lineCount % 1000 === 0) {
   process.stdout.write(`\rüßÆ Processed: ${lineCount.toLocaleString()} lines`);
  }
 }
Increment line count.

Log progress every 1000 lines in-place using \r to overwrite the previous log.
 console.log(`\r‚úÖ Finished processing ${lineCount.toLocaleString()} lines.`);
 console.log("üíæ Writing results to", outputFile, "...");
Log completion of processing.

 fs.writeFileSync(outputFile, JSON.stringify(domainCounts, null, 2));
 const duration = ((Date.now() - startTime) / 1000).toFixed(2);
 console.log(`üéâ Done! (${duration}s total) Results in ${outputFile}`);
Write domainCounts to JSON file in a human-readable format (2-space indentation).

Log total duration and location of results.

main().catch((err) => console.error(err.message));
Run main() and catch any errors to display in the console.

4Ô∏è‚É£ Example Input (users.csv)
id,email
1,asmi@gmail.com
2,riya@yahoo.com
3,aman@gmail.com
4,meena@outlook.com
5,riya@gmail.com
5Ô∏è‚É£ Example Output (domains.json)
{
  "gmail.com": 3,
  "yahoo.com": 1,
  "outlook.com": 1
}
6Ô∏è‚É£ How to Run
npm run start
Progress will be shown in console.

JSON file is saved in out/domains.json.

